{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proportion_in_different_network_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWlspmupXtgY",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDgnqEFEXoj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install mesa==0.8.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Qb-0-YsXEK",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGnZ_gRFsYjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Sep 26 16:41\n",
        "\n",
        "Tue May 5, 10:39 2020\n",
        "v0.15: Update price function, minimum threshold to become a member, portion of \n",
        "       attitude or subjective norm.\n",
        "\n",
        "Tue Apr 28 10:14 2020\n",
        "v0.14: Change the flow of attitude and subjective norm to follow the extensive\n",
        "       game that models the situation better.\n",
        "\n",
        "Sun Jan 12 16:50 2019\n",
        "v0.13: Clean up codes after introducing TPB into the model.\n",
        "\n",
        "Wed Dec 25 21:25 2019\n",
        "v0.12: Set baseline for new improvement.\n",
        "\n",
        "Tue Nov 26 18:39 2019\n",
        "v0.11: Added parameters for consensus and conflict payoff. \n",
        "\n",
        "Sun Nov 24 11:53 2019\n",
        "v0.10: Added aspiration-based learning and changed the logic that all members\n",
        "       consider to exit if a conflict occurs. \n",
        "\n",
        "Tue Nov 12 19:30 2019\n",
        "v0.9: Added a function to exit the group after experiencing conflicts. \n",
        "\n",
        "Tue Nov 12 14:13 2019\n",
        "v0.8: Added a function to calculate new learning level after experiencing\n",
        "      conflicts. \n",
        "\n",
        "Sun Nov 10 18:11 2019\n",
        "v0.7: Updated the comments. \n",
        "\n",
        "Sat Nov 9 22:07 2019\n",
        "v0.6: Changed substantially to include conflict process and group task status.      \n",
        "\n",
        "v0.5: Updated maximum working hours per agent based on learning rate of all \n",
        "      agents in a task.\n",
        "\n",
        "@author: Albert Yosua\n",
        "\"\"\"\n",
        "\n",
        "from mesa import Agent, Model\n",
        "from mesa.time import RandomActivation\n",
        "from mesa.datacollection import DataCollector\n",
        "\n",
        "#from scipy.stats import truncnorm\n",
        "\n",
        "import random\n",
        "#import numpy\n",
        "#import itertools\n",
        "import networkx as nx\n",
        "import math\n",
        "#import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class FarmerAgent(Agent):\n",
        "    \"\"\" An agent.\"\"\"\n",
        "    def __init__(self, \n",
        "                 unique_id, \n",
        "                 model,\n",
        "                 learning_rate\n",
        "                 ):\n",
        "        super().__init__(unique_id, model)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.aspiration = 0 # Real value\n",
        "        self.total_payoff = 0\n",
        "        self.current_payoff = 0\n",
        "        # Two intentions determining the conflict-resolving behavior\n",
        "#        self.assertiveness = 0.9\n",
        "#        self.cooperativeness = 0\n",
        "#        self.cooperativeness = random.choice([0.1])\n",
        "#        self.cooperativeness = round(random.uniform(0.1, 0.9), 1)        \n",
        "#        self.subjective_norm = round(random.uniform(0.1, 0.9), 1)        \n",
        "#        self.attitude = round(random.uniform(0.6, 0.9), 1)\n",
        "        self.attitude = 0\n",
        "#        self.attitude = 0.6\n",
        "#        self.subjective_norm = self.attitude\n",
        "#        self.subjective_norm = round(random.uniform(0.1, 0.9), 1)\n",
        "        self.subjective_norm = 0\n",
        "#        self.behavioral_control = self.attitude\n",
        "        self.behavioral_control = round(random.uniform(0.1, 0.9), 1)\n",
        "#        self.behavioral_control = self.attitude\n",
        "        self.intention = 0\n",
        "        self.aspiration_rescaling = 0\n",
        "        self.stimulus = 0\n",
        "        self.exit = 0\n",
        "        self.member = 0\n",
        "        self.survive = 0\n",
        "    \n",
        "    def step(self):\n",
        "        # Aspiration will be updated as long as the agent has not exited\n",
        "        # or not yet a member\n",
        "        if self.exit == 0:\n",
        "            update_aspiration_static_ex(self)\n",
        "#            calculate_payoff_static_ex(self)\n",
        "        else:\n",
        "            self.stimulus = 0\n",
        "            self.current_payoff = 0\n",
        "        \n",
        "        self.total_payoff += self.current_payoff\n",
        "\n",
        "def update_aspiration_static_ex(self):\n",
        "    # Previous step's value\n",
        "    # Amount of money that an agents aspires to get in joining co-op\n",
        "    asp = self.aspiration\n",
        "    profit = 0\n",
        "    \n",
        "    if self.member == 1:      \n",
        "        # During joining the co-op, an agent checks profit they receive\n",
        "        # Update aspiration value based on received profit\n",
        "        if self.model.farmer_profit_amount > 0:           \n",
        "            profit = self.model.farmer_profit_amount\n",
        "            \n",
        "            # Update aspiration\n",
        "            dynamic = self.model.is_aspiration_dynamic           \n",
        "            if dynamic:\n",
        "                # Only the best payoff to be aspiration value\n",
        "#                if profit > self.aspiration:\n",
        "#                    self.aspiration = profit\n",
        "                 # Habituation concept\n",
        "                 h = self.model.learning_rate_asp                 \n",
        "                 self.aspiration = (1 - h) * asp + h * profit\n",
        "        \n",
        "#        self.total_payoff = profit\n",
        "    \n",
        "        # Real value\n",
        "        self.stimulus = profit - asp\n",
        "        \n",
        "        # Update the attitude level.    \n",
        "        stimulus = self.stimulus\n",
        "        \n",
        "    #    s = stimulus / self.model.max_payoff\n",
        "        if stimulus != 0 and asp != 0:\n",
        "            s = stimulus / self.model.max_payoff\n",
        "        else:\n",
        "            s = 0\n",
        "        \n",
        "    #    print(\"s:\", s)\n",
        "            \n",
        "    #    l_r = 0.3\n",
        "        l_r = self.learning_rate\n",
        "        a = self.attitude\n",
        "    \n",
        "        if s >= 0:        \n",
        "            a = a + (1 - a) * l_r * s\n",
        "        else:        \n",
        "            a = a + a * l_r * s\n",
        "    \n",
        "        self.attitude = a\n",
        "        \n",
        "    else:\n",
        "        # Current decision is still not joining the co-op\n",
        "        profit = 0\n",
        "\n",
        "\n",
        "    \n",
        "    self.current_payoff = profit\n",
        "#    self.total_payoff += profit\n",
        "\n",
        "\n",
        "#    print(\"{:.2f}\".format(self.attitude))\n",
        "    \n",
        "    # Update the subjective norm level\n",
        "     # Get other agents connected to this agent.\n",
        "    connections = list(self.model.network.neighbors(self.unique_id))\n",
        "    \n",
        "    # Update the value of cooperativeness level based on other agents' values.\n",
        "    # Based on Friedkin and Johnsen, 2011\n",
        "    if len(connections) > 0:\n",
        "        n = len(connections)\n",
        "        agents_list = [agent for agent in self.model.schedule.agents\n",
        "                       if agent.unique_id in connections]\n",
        "        \n",
        "        sum_cooperativeness = 0\n",
        "#        for agent in agents_list:\n",
        "#            peer_cooperativeness = 0            \n",
        "#            if agent.cooperativeness > 0.50:\n",
        "#                peer_cooperativeness = 1                \n",
        "#            sum_cooperativeness += (1 / n) \\\n",
        "#                * (peer_cooperativeness - self.subjective_norm)        \n",
        "        for agent in agents_list:\n",
        "            peer_cooperativeness = 0            \n",
        "            if agent.member == 1:\n",
        "                peer_cooperativeness = 1                \n",
        "            sum_cooperativeness += (1 / n) \\\n",
        "                * (peer_cooperativeness - self.subjective_norm) \n",
        "            \n",
        "        self.subjective_norm += self.model.learning_rate_sn \\\n",
        "                                * sum_cooperativeness\n",
        "#        self.subjective_norm += self.learning_rate * sum_cooperativeness\n",
        "        \n",
        "    # Make sure the upper and lower range is between 0 and 1.\n",
        "    if self.subjective_norm > 1:\n",
        "        self.subjective_norm = 1\n",
        "    elif self.subjective_norm < 0:\n",
        "        self.subjective_norm = 0\n",
        "    \n",
        "#    # Update aspiration ---> moved to model step\n",
        "#    # Range: [0,1]\n",
        "#    attitude_portion = self.model.attitude_portion\n",
        "#    if self.member == 0:\n",
        "#        # Not already joined members only use the subjective norm\n",
        "##        attitude_portion = 0.5\n",
        "#        attitude_portion = 0.5\n",
        "##    if self.member == 1 and \\\n",
        "##        self.exit == 0 and \\\n",
        "##        self.unique_id in self.model.joined_agents_list:\n",
        "##        attitude_portion = 1.0\n",
        "#    self.aspiration_rescaling = (1 - attitude_portion) * self.subjective_norm \\\n",
        "#                                + attitude_portion * self.attitude\n",
        "\n",
        "#    # Update intention ---> moved to model step                               \n",
        "#    self.intention = self.aspiration_rescaling\n",
        "    \n",
        "#    # Update membership    ---> moved to model step\n",
        "##    if self.intention <= 0.50 or self.subjective_norm <= 0.50:\n",
        "#    if self.intention <= 0.50:\n",
        "#        # Exit co-op if currently a member and thinks that it is not worth\n",
        "#        if self.member == 1:\n",
        "#            # Survive is effective for a newly joined members in high join\n",
        "#            # portion initialisation value\n",
        "#            if self.survive >= 0:\n",
        "#                self.exit = 1\n",
        "#            else:\n",
        "#                self.survive += 1            \n",
        "#    else:\n",
        "#        # If not yet join, next step is to become a member\n",
        "#        if self.member == 0:\n",
        "#            self.member = 1\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def update_aspiration(self):   \n",
        "    \n",
        "    attitude_portion = self.model.attitude_portion\n",
        "#    if self.member == 0 and self.exit == 0:\n",
        "#        # Not already joined members only use the subjective norm\n",
        "##        attitude_portion = 0.5\n",
        "#        attitude_portion = 0.5\n",
        "    # Range: [0,1]\n",
        "    self.aspiration_rescaling = (1 - attitude_portion) * self.subjective_norm \\\n",
        "                                + attitude_portion * self.attitude\n",
        "    \n",
        "def update_intention(self):\n",
        "    self.intention = self.aspiration_rescaling\n",
        "\n",
        "def update_membership(self):\n",
        "#    if self.intention <= self.model.exit_threshold:\n",
        "#        # Exit co-op if currently a member and thinks that it is not worth\n",
        "#        if self.member == 1:\n",
        "#            # Survive is effective for a newly joined members in high join\n",
        "#            # portion initialisation value\n",
        "#            if self.survive >= self.model.survive_threshold:\n",
        "#                self.exit = 1\n",
        "#            else:\n",
        "#                self.survive += 1            \n",
        "#    else:\n",
        "#        # If not yet join, next step is to become a member\n",
        "#        if self.member == 0:\n",
        "#            self.member = 1\n",
        "            \n",
        "    # If not a member\n",
        "    if self.member == 0:\n",
        "        # Enter co-op if currently not a member\n",
        "        if self.intention >= self.model.enter_threshold:\n",
        "            self.member = 1\n",
        "    # If a member or previously a member\n",
        "    else:\n",
        "        # If not yet exit\n",
        "        if self.exit == 0:\n",
        "            # Exit co-op if currently a member\n",
        "            if self.intention < self.model.exit_threshold:\n",
        "                self.exit = 1\n",
        "   \n",
        "\n",
        "#def get_truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
        "#\n",
        "#    return truncnorm(\n",
        "#        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
        "    \n",
        "    \n",
        "def get_total_cooperative_agents(model):\n",
        "    cooperative_agents = sum(1 for agent \n",
        "                         in model.schedule.agents \n",
        "                         if agent.exit == 0 and agent.member == 1)\n",
        "    \n",
        "    return cooperative_agents\n",
        "\n",
        "def get_farmer_profit_amount(model):\n",
        "    return model.farmer_profit_amount\n",
        "\n",
        "\n",
        "def get_total_defective_agents(model):\n",
        "    cooperative_agents = sum(1 for agent \n",
        "                         in model.schedule.agents \n",
        "                         if not (agent.exit == 0 and agent.member == 1))\n",
        "    \n",
        "    return cooperative_agents\n",
        "\n",
        "            \n",
        "class FarmerModel(Model):\n",
        "    \"\"\"A model with some number of agents.\"\"\"\n",
        "    def __init__(self, \n",
        "                 N, \n",
        "                 learning_rate,\n",
        "                 learning_rate_sn,\n",
        "                 nearest_neighbors_number,\n",
        "                 joined_agents,\n",
        "                 is_aspiration_dynamic,\n",
        "                 is_initial_members_pos_random,\n",
        "                 attitude_portion,\n",
        "                 enter_threshold,\n",
        "                 exit_threshold,\n",
        "                 survive_threshold,\n",
        "                 learning_rate_asp,\n",
        "                 profit_noise_max,\n",
        "                 profit_noise_min,\n",
        "                 network_type,\n",
        "                 seed=None\n",
        "                 ):\n",
        "        \n",
        "        self.num_agents = N\n",
        "        self.learning_rate_sn = learning_rate_sn\n",
        "        self.nearest_neighbors_number = nearest_neighbors_number\n",
        "        self.is_aspiration_dynamic = is_aspiration_dynamic       \n",
        "        self.is_initial_members_pos_random = is_initial_members_pos_random\n",
        "        self.attitude_portion = attitude_portion\n",
        "        self.enter_threshold = enter_threshold\n",
        "        self.exit_threshold = exit_threshold\n",
        "        self.survive_threshold = survive_threshold\n",
        "        self.learning_rate_asp = learning_rate_asp\n",
        "        self.profit_noise_max = profit_noise_max\n",
        "        self.profit_noise_min = profit_noise_min\n",
        "        self.network_type = network_type\n",
        "        \n",
        "        self.schedule = RandomActivation(self)\n",
        "        # For batch set up\n",
        "        self.running = True\n",
        "        \n",
        "        if self.network_type == 0:\n",
        "            # Create a network\n",
        "            # n - the number of nodes\n",
        "            # k - each node is joined with its k nearest neighbours\n",
        "            # p - the probability of rewiring each edge\n",
        "            self.network = nx.watts_strogatz_graph(n=self.num_agents, \n",
        "                                                   k=self.nearest_neighbors_number, \n",
        "                                                   p=0.1, \n",
        "                                                   seed=seed)\n",
        "        elif self.network_type == 1:\n",
        "            self.network = nx.extended_barabasi_albert_graph(n=self.num_agents, \n",
        "                                                             m=self.nearest_neighbors_number, \n",
        "                                                             p=0.1, \n",
        "                                                             q=0.1, \n",
        "                                                             seed=seed)\n",
        "        \n",
        "        \n",
        "#        self.network = nx.watts_strogatz_graph(10, 2, 0.1, seed=1)\n",
        "#        self.network = nx.extended_barabasi_albert_graph(n=10, \n",
        "#                                                         m=3, \n",
        "#                                                         p=0.1, \n",
        "#                                                         q=0.1, \n",
        "#                                                         seed=1)\n",
        "#        self.network = nx.extended_barabasi_albert_graph(n=10, m=1, p=0.1, \n",
        "#                                                         q=0.1, seed=1)\n",
        "        \n",
        "        \n",
        "#        degree_sequence = sorted([d for n, d \n",
        "#                              in self.network.degree()], reverse=True)\n",
        "        \n",
        "        # Range: [0, x_max].\n",
        "        # Assume both cooperative agents get the maximum payoff.\n",
        "#        self.max_payoff = max(degree_sequence) * self.both_coll_payoff\n",
        "        \n",
        "        # Create agents based on node ID from the network\n",
        "#        for i in range(self.num_agents):\n",
        "        for i in self.network:\n",
        "            a = FarmerAgent(i, self, \n",
        "                            learning_rate,\n",
        "#                            max_aspiration,\n",
        "#                            min_aspiration,\n",
        "#                            both_coll_payoff,\n",
        "#                            both_comp_payoff\n",
        "                            )            \n",
        "#            update_aspiration(a)  \n",
        "#            update_intention(a)\n",
        "#            update_cooperativeness(a)\n",
        "            \n",
        "#            update_subjective_norm(a)\n",
        "            self.schedule.add(a)      \n",
        "            \n",
        "        # Update initial joined status\n",
        "        joined_agents_num = round(joined_agents*N)\n",
        "        \n",
        "        pos_random = self.is_initial_members_pos_random\n",
        "        if pos_random:\n",
        "            # Select randomly\n",
        "            joined_agents_list = random.sample(range(joined_agents_num), \n",
        "                                               joined_agents_num)\n",
        "        \n",
        "        else:\n",
        "            # Select from top number of degrees\n",
        "            sorted_degrees = sorted([(d, n) for n, d in self.network.degree()], \n",
        "                                     reverse=True)\n",
        "            joined_agents_list = [n for d, n in \n",
        "                                  sorted_degrees[:joined_agents_num]]\n",
        "        \n",
        "        # All calls to random will output the same results \n",
        "#        random.seed(1)\n",
        "        \n",
        "        initial_members_threshold_bottom = self.enter_threshold\n",
        "        initial_members_threshold_top = 0.99\n",
        "        initial_non_members_threshold_bottom = 0.00\n",
        "        initial_non_members_threshold_top = self.enter_threshold - 0.01\n",
        "        \n",
        "        self.joined_agents_list = joined_agents_list\n",
        "        for a in self.schedule.agents:            \n",
        "            # Initial members of a co-op\n",
        "            if a.unique_id in joined_agents_list:\n",
        "                a.attitude = \\\n",
        "                    round(self.random.\n",
        "                          uniform(initial_members_threshold_bottom,\n",
        "                                  initial_members_threshold_top), 2)\n",
        "                a.subjective_norm = \\\n",
        "                    round(self.random.\n",
        "                          uniform(initial_members_threshold_bottom,\n",
        "                                  initial_members_threshold_top), 2)\n",
        "            # Outsider\n",
        "            else:\n",
        "                a.attitude = \\\n",
        "                    round(self.random.\n",
        "                          uniform(initial_non_members_threshold_bottom,\n",
        "                                  initial_non_members_threshold_top), 2)\n",
        "#                a.attitude = round(random.uniform(0.1, 0.5), 1)\n",
        "                a.subjective_norm = \\\n",
        "                    round(self.random.\n",
        "                          uniform(initial_non_members_threshold_bottom,\n",
        "                                  initial_non_members_threshold_top), 2)\n",
        "#                a.subjective_norm = round(random.uniform(0.6, 0.9), 1)\n",
        "            update_aspiration(a)  \n",
        "            update_intention(a)\n",
        "#            update_cooperativeness(a)\n",
        "            \n",
        "        # Outsider -> Consider -> Member\n",
        "        \n",
        "        # Put the initial member to the highest degree of network\n",
        "        \n",
        "#        for a in self.schedule.agents:\n",
        "#            update_aspiration(a)\n",
        "#            update_intention(a)\n",
        "#            update_cooperativeness(a)\n",
        "            \n",
        "        # Count how many agents joined the co-op (at initialisation only)\n",
        "        self.join = 0;\n",
        "        self.join = sum(1 for agent \n",
        "                        in self.schedule.agents \n",
        "                        if agent.intention > self.enter_threshold)\n",
        "        \n",
        "#        count = 0\n",
        "        for a in self.schedule.agents:\n",
        "            if a.intention > 0.50:\n",
        "                a.member = 1\n",
        "            # Take some outsiders to become members\n",
        "            else:\n",
        "                if a.intention > self.enter_threshold:\n",
        "                    a.member = 1\n",
        "#                    count += 1\n",
        "        \n",
        "        self.coop_profit_ratio = 0.2\n",
        "        self.farmer_profit_ratio = 0.8 \n",
        "        \n",
        "#        members_portion = self.join / self.num_agents\n",
        "#        sigmoid_val = 1/(1+math.exp(-20*(members_portion-0.1)))\n",
        "#        self.profit_amount = 100 * sigmoid_val\n",
        "        \n",
        "#        self.profit_amount = round(random.uniform(10, 100), 1)\n",
        "        \n",
        "#        self.profit_amount = 10 * self.join\n",
        "        \n",
        "        # Proportional profit\n",
        "#        portion = self.join / self.num_agents\n",
        "#        self.profit_amount = portion**2 * 1000\n",
        "#        self.max_payoff = self.farmer_profit_ratio / self.num_agents * 1000\n",
        "\n",
        "        # Linear profit\n",
        "#        self.profit_amount = 10 * self.join\n",
        "#        self.max_payoff = 10 * self.num_agents\n",
        "        \n",
        "        # Logistic \n",
        "        self.var_b = 0.8\n",
        "        portion = self.join / self.num_agents\n",
        "        sigmoid_val = 1 / (1 + math.exp(-10 * (portion - self.var_b)))        \n",
        "        self.profit_amount = sigmoid_val * 1000\n",
        "#        self.max_payoff = self.farmer_profit_ratio / self.num_agents \\\n",
        "#                          * (1 / (1 + math.exp(-10 * (1 - self.var_b)))) * 1000\n",
        "#        self.max_payoff = 80\n",
        "        \n",
        "        # NOTE: develop max_payoff so it can be calculated by given function\n",
        "        a = pd.Series(list(range(1, self.num_agents+1)))\n",
        "        a = a.divide(50)\n",
        "        b = a.apply(lambda x: (1 / (1 + math.exp(-10 * (x - self.var_b)))) \\\n",
        "                    * 1000 *  self.farmer_profit_ratio / (x * self.num_agents))\n",
        "        self.max_payoff = b.max()\n",
        "        \n",
        "        if self.join == 0:\n",
        "            self.farmer_profit_amount = 0\n",
        "        else:\n",
        "            self.farmer_profit_amount = self.farmer_profit_ratio / self.join \\\n",
        "                                        * self.profit_amount        \n",
        "        \n",
        "#        self.max_payoff = self.farmer_profit_ratio * self.profit_amount\n",
        "#        print(self.max_payoff)\n",
        "                                           \n",
        "        # Initial aspiration equals to the received profit\n",
        "        for a in self.schedule.agents:\n",
        "#            a.aspiration = self.farmer_profit_amount\n",
        "            \n",
        "            \n",
        "            # Initial aspiration value\n",
        "            \n",
        "            # Low - 1 person\n",
        "#            a.aspiration = self.max_payoff / self.num_agents\n",
        "            \n",
        "            # High - 10 persons\n",
        "#            a.aspiration = self.farmer_profit_ratio / self.num_agents \\\n",
        "#                           * (1 / (1 + math.exp(-10 * (0.1 - self.var_b)))) \\\n",
        "#                           * 1000\n",
        "            # Based on 10 persons\n",
        "#            a.aspiration = b.iloc[9]\n",
        "            \n",
        "            # Based on percentage from the max payoff\n",
        "            a.aspiration = 0.1 * self.max_payoff\n",
        "                        \n",
        "\n",
        "    \n",
        "#            else:\n",
        "#                a.aspiration = 0\n",
        "                \n",
        "#        print(\"Initial joined agents:\", self.join)\n",
        "#        for a in self.schedule.agents:\n",
        "#            a.aspiration = self.farmer_profit_amount\n",
        "\n",
        "\n",
        "#            print(\"Initial:\", a.aspiration, self.farmer_profit_amount)\n",
        "            \n",
        "#        update_all_subjective_norm(self)        \n",
        "            \n",
        "        self.datacollector = DataCollector(\n",
        "        # A function to call\n",
        "        model_reporters={\"cooperative_agents\": get_total_cooperative_agents,\n",
        "                         \"defective_agents\": get_total_defective_agents,\n",
        "                         \"farmer_profit\": get_farmer_profit_amount\n",
        "                         },  \n",
        "        # An agent attribute\n",
        "        agent_reporters={\"current_payoff\": \"current_payoff\",\n",
        "                         \"aspiration\": \"aspiration\",\n",
        "                         \"total_payoff\": \"total_payoff\",\n",
        "                         \"stimulus\": \"stimulus\",\n",
        "                         \"attitude\": \"attitude\",\n",
        "                         \"member\": \"member\",\n",
        "                         \"exit\": \"exit\",\n",
        "                         \"subjective_norm\": \"subjective_norm\",\n",
        "                         \"intention\": \"intention\",  \n",
        "                         \"survive\": \"survive\",\n",
        "                         \"behavioral_control\": \"behavioral_control\",\n",
        "                         \"aspiration_rescaling\": \"aspiration_rescaling\",\n",
        "                         })  \n",
        "    def step(self):\n",
        "        self.datacollector.collect(self)\n",
        "        '''Advance the model by one step.'''\n",
        "        self.schedule.step()\n",
        "        \n",
        "        # Update cooperativeness of all agents simultaneously\n",
        "#        update_all_cooperativeness(self)\n",
        "        \n",
        "        \n",
        "        \n",
        "        for agent in self.schedule.agents:\n",
        "            if agent.exit == 0:\n",
        "                update_aspiration(agent)\n",
        "                update_intention(agent)\n",
        "                update_membership(agent)\n",
        "        \n",
        "        # Count how many agents joined the co-op\n",
        "        self.join = sum(1 for agent \n",
        "                        in self.schedule.agents \n",
        "                        if agent.exit == 0 and\n",
        "                        agent.member == 1)\n",
        "        \n",
        "        # Based on time\n",
        "#        self.profit_amount = self.schedule.steps * 100 \\\n",
        "#                             * round(random.uniform(0.6, 0.9), 1)\n",
        "        \n",
        "        # Update new profit for next step according to specific criteria\n",
        "#        self.profit_amount = round(random.uniform(900, 1000), 1)\n",
        "        \n",
        "        # Use sigmoid function\n",
        "#        members_portion = self.join / self.num_agents\n",
        "#        sigmoid_val = 1/(1+math.exp(-20*(members_portion-0.1)))\n",
        "#        self.profit_amount = 100 * sigmoid_val\n",
        "        \n",
        "        # y = 10x\n",
        "        # The profit is linear with increasing number of members\n",
        "#        self.profit_amount = 10 * self.join\n",
        "        \n",
        "        # Proportional profit\n",
        "#        portion = self.join / self.num_agents\n",
        "#        self.profit_amount = portion**2 * 1000\n",
        "        \n",
        "        # Linear profit\n",
        "#        self.profit_amount = 10 * self.join\n",
        "        \n",
        "        # Logistic profit\n",
        "        portion = self.join / self.num_agents\n",
        "        sigmoid_val = 1 / (1 + math.exp(-10 * (portion - self.var_b)))\n",
        "        self.profit_amount = sigmoid_val * 1000\n",
        "        \n",
        "        if self.join == 0:\n",
        "            self.farmer_profit_amount = 0\n",
        "        else:\n",
        "            self.farmer_profit_amount = self.farmer_profit_ratio / self.join \\\n",
        "                                        * self.profit_amount\n",
        "            \n",
        "            # Set the range of noise to profit\n",
        "            noise = self.random.randint(self.profit_noise_min, \n",
        "                                   self.profit_noise_max)\n",
        "#            print(noise)\n",
        "#            noise = random.randint(0, 0)\n",
        "            if (noise + self.farmer_profit_amount) < self.max_payoff and \\\n",
        "                (noise + self.farmer_profit_amount) > 0:\n",
        "                self.farmer_profit_amount += noise\n",
        "                                        \n",
        "#        print(\"Joined:\", self.join,\n",
        "#              \"Profit:\", \"{:.2f}\".format(self.profit_amount), \n",
        "#              \"Share:\", \"{:.2f}\".format(self.farmer_profit_amount))\n",
        "        \n",
        "#        verify_available_working_status(self)\n",
        "#        verify_completed_working_status(self)\n",
        "                                        \n",
        "#        for a in self.schedule.agents:    \n",
        "#            if a.cooperativeness <= 0.50:\n",
        "#                a.exit = 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsJgxHnjsgTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "9630d4bf-5639-48c3-da3b-7d3373dcd677"
      },
      "source": [
        "# run_batch_r_sn_n.py\n",
        "\n",
        "from mesa.batchrunner import BatchRunner\n",
        "\n",
        "# from model import FarmerModel\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "num_iterations = 2\n",
        "#number_of_agents = 50\n",
        "number_of_steps = 30\n",
        "\n",
        "fixed_params = {\"N\": 50,  # Number of agents\n",
        "                \"learning_rate\": 0.35,\n",
        "                \"learning_rate_sn\": 0.15,\n",
        "#                \"nearest_neighbors_number\": 5,\n",
        "                \"joined_agents\": 0.4,\n",
        "                \"is_aspiration_dynamic\": 0, # Static: 0, Dynamic: 1\n",
        "#                \"is_initial_members_pos_random\": 0, # High conn.: 0, Random: 1\n",
        "                \"attitude_portion\": 0.2,\n",
        "                \"enter_threshold\": 0.4,\n",
        "                \"exit_threshold\": 0.3,\n",
        "                \"survive_threshold\": 0,\n",
        "                \"learning_rate_asp\": 0.9,\n",
        "                \"profit_noise_max\": 5,\n",
        "                \"profit_noise_min\": -5,\n",
        "                \"network_type\": 1, # WS = 0, BA = 1\n",
        "                }\n",
        "\n",
        "range_1 = [2, 3, 4, 5, 6] # BA, nearest_neighbors_number - barabasi albert [1]\n",
        "\n",
        "# range_1 = [4, 6, 8, 10, 12] # WS, nearest_neighbors_number - watts strogatz [0]\n",
        "\n",
        "range_2 = [0, 1] # is_initial_members_pos_random\n",
        " \n",
        "# Note: changing the value of parameter should be applied to plot section below\n",
        "variable_params = {\"nearest_neighbors_number\": range_1,\n",
        "                   \"is_initial_members_pos_random\": range_2\n",
        "                   }\n",
        "\n",
        "batch_run = BatchRunner(FarmerModel,\n",
        "                        fixed_parameters=fixed_params,\n",
        "                        variable_parameters=variable_params,\n",
        "                        iterations=num_iterations,\n",
        "                        max_steps=number_of_steps,\n",
        "                        model_reporters={\n",
        "#                            \"Mean\": compute_mean,\n",
        "#                            \"Stdev\": compute_stdev,\n",
        "                            \"datacollector\": lambda m: m.datacollector,\n",
        "#                            \"completed_time\": lambda m: m.completed_time\n",
        "                            },\n",
        "#                        agent_reporters={\n",
        "#                                \"State\": lambda a: a.current_state, \n",
        "#                              \"Reward\": lambda a: a.reward, \n",
        "#                             }\n",
        "                        )\n",
        "batch_run.run_all()\n",
        "\n",
        "\n",
        "\n",
        "#plt.ylim(ymax=9)\n",
        "#\n",
        "#run_data = batch_run.get_model_vars_dataframe()\n",
        "#run_data.head()\n",
        "#plt.scatter(run_data.N, run_data.Mean, s=5)\n",
        "\n",
        "run_data = batch_run.get_model_vars_dataframe()\n",
        "\n",
        "#run_data_agent = batch_run.get_agent_vars_dataframe()\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statistics \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "#df_collection = {}\n",
        "df_collection = pd.DataFrame(data=None, index=range_2, columns=range_1)\n",
        "df_initial_collection = pd.DataFrame(data=None, index=range_2, columns=range_1)\n",
        "\n",
        "for j in range_1:\n",
        "    \n",
        "    for k in range_2:\n",
        "    \n",
        "        df_temp_0 = run_data.query('nearest_neighbors_number==' + str(j) + ' and '\n",
        "                               + 'is_initial_members_pos_random==' + str(k))\n",
        "    \n",
        "#    df_temp_0 = run_data.query('learning_rate==' + str(j))\n",
        "    \n",
        "        count = 0\n",
        "        initial_members = []\n",
        "        cooperative_agents = []\n",
        "    #        ax = plt.gca()\n",
        "    #    fig, (ax_1, ax_2) = plt.subplots(1,2,figsize=(8,4))\n",
        "    #    fig, (ax_1) = plt.subplots(1,1,figsize=(8,4))\n",
        "        for i in df_temp_0.iterrows():\n",
        "            # Get each agent data\n",
        "            df_temp \\\n",
        "                = i[1]['datacollector'].get_model_vars_dataframe().copy()    \n",
        "                \n",
        "            # Get all agents in specific status\n",
        "            df_temp_count = df_temp.query('index == ' + str(number_of_steps - 1))\n",
        "            \n",
        "            cooperative_agents.append(df_temp_count.iloc[0]['cooperative_agents'])\n",
        "            \n",
        "            diff = df_temp.iloc[-1]['cooperative_agents'] - \\\n",
        "                   df_temp.iloc[0]['cooperative_agents']\n",
        "            \n",
        "            initial_members.append(diff)\n",
        "    \n",
        "#        plt.scatter(x=np.arange(0, num_iterations),\n",
        "#                    y=cooperative_agents, \n",
        "#                    marker='o',\n",
        "#                    label=j)    \n",
        "    #    plt.ylim(-1, number_of_agents + 1)  \n",
        "#        plt.ylim(-1, 50 + 1)\n",
        "#        plt.legend()\n",
        "    #    plt.figure(figsize=(4, 4))\n",
        "    \n",
        "#        print(k, j, cooperative_agents)\n",
        "        df_collection.loc[k][j] = statistics.mean(cooperative_agents)\n",
        "        df_initial_collection.loc[k][j] = statistics.mean(initial_members)\n",
        "        \n",
        "#        df_collection[str(j)+'_'+str(k)] = cooperative_agents\n",
        "\n",
        "#    # Convert to dataframe\n",
        "#    df_all = pd.DataFrame(df_collection)    \n",
        "#    \n",
        "#    df_all.mean().plot(ylim=(-1,51), figsize=(4,4))\n",
        "    \n",
        "df_collection.T.plot(figsize=(4,4),ylim=(-1,51))\n",
        "plt.xlabel('nearest_neighbors_number')\n",
        "df_initial_collection.T.plot(figsize=(4,4),ylim=(-51,51))\n",
        "plt.xlabel('nearest_neighbors_number')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20it [00:00, 27.40it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'nearest_neighbors_number')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEHCAYAAACutfPgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATZUlEQVR4nO3dfZBV9X3H8fdHFl0FFIGVGC66GHwIMSMmK40lNUaTqCRBOzVWmmSgYpl2TGMeZhKTzrSm0wftNJq0dtoaTWVS47MGYxoiJZJEa8DFZ0GCAVSohhWfMCnqLt/+cX7IsmHZu/dxd3+f18zOPefcc373ey6cz/2dc885VxGBmeVrv2YXYGbN5RAwy5xDwCxzDgGzzDkEzDLX0sgXmzRpUrS3tzfyJc0MWL169QsR0ba358oKAUmbgO1AD9AdER2SJgA3Ae3AJuC8iHhpX+20t7fT2dlZfuVmVhOSnu7vucHsDnwwImZGREcavwRYHhFHA8vTuJkNM9XsDpwNnJqGFwMrgC9XWc/IEQG/2QbdO5pdiY1kow+CgyZU1US5IRDA3ZIC+PeIuBqYHBHPpeefByZXVUnyte8/wZr/fbUWTTVGBIfu3MbU7qcpdT/DlDefoZSGx8Zrza7ORriHJ5zFzM/eWFUb5YbA+yNii6TDgGWSnuz9ZERECojfImkRsAjgiCOOqKrYpopg4s4uSm8+w9Tup5mSNvRS9zMcFL95a7btGsfm0Udy/4GnsKXlCHaotYlFWy21jN6f6e98LweNPRhQs8sBQKNaWLt27Vvjra2tlEolRo8eXX4bg712QNKlwGvAnwCnRsRzkg4HVkTEsftatqOjI4b8gcGdO+GVZ6BrHXQ9CVufLB5f+AW80euTfUwbtB0Hbcemx/Q3ZhJoaPwHsdrauHEj48aNY+LEiWgI/htHBNu2bWP79u1MmzZtj+ckre51PG8PA/YEJI0B9ouI7Wn4I8BfA3cC84HL0uOSKtehsXb2wEubdm/sXeugay28sB7e3P3Jzti3FRv6zE/uucGPmdi00q05duzYQXt7+5AMAABJTJw4ka6urkEtV87uwGTgjrTiLcB3I2KppAeAmyUtBJ4GzhtkzY3R0w0vbUwb+pO7N/oX1u950O7gKcVG/t7ZvTb2Y+HAQ5tXuw05QzUAdqmkvgFDICI2ACfsZfo24PRBv2K99LwJL27YswvftQ62rYeeN3bPd8jUYgOf9oFe3fhjoPWQ5tVu1kQNPWOwJrpfh22/3LML37UOtj0FO7t3zzf+yGIDP/pDuz/VJx0DB4xrXu1mVVq6dCkXX3wxPT09XHjhhVxySfWn5wzdEHhzR/Ep/tY+e/qEf3EDRE+aSTBhWrGRH3sWtL0zbexHw/5jmlq+Wa319PRw0UUXsWzZMkqlEieddBJz585lxowZVbU79ELgrs/Dhp8U+/Gxs5imUTDhqGIDn3F2sdEfdhxMnA6jD2xuvWYNsmrVKqZPn85RRx0FwPnnn8+SJUtGYAggeNvx8O5z0wG6d8LEd0DLAc0uzOwt9TipbcbbD+avPv6ufp/fsmULU6dOfWu8VCqxcuXKql936IXAx65odgVmWRl6IWA2DOzrE7tepkyZwrPPPvvW+ObNm5kyZUrV7fqmImbDxEknncT69evZuHEjb7zxBjfeeCNz586tul33BMyGiZaWFq666irOOOMMenp6uOCCC3jXu6rvkTgEzIaROXPmMGfOnJq26d0Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDAbRi644AIOO+wwjj/++Jq16RAwG0YWLFjA0qVLa9qmQ8BsGDnllFOYMKG63xnoy2cMmlXih5fA84/Vts23vRvOuqy2bZbBPQGzzLknYFaJJnxi14t7AmaZcwiYDSPz5s3j5JNPZt26dZRKJa699tqq2/TugNkwcsMNN9S8TfcEzDLnEDDLnEPAbBAG+yvejVZJfQ4BszK1traybdu2IRsEu36avLW1dVDL+cCgWZlKpRKbN28e9E9/N1JrayulUmlQyzgEzMo0evRopk2b1uwyas67A2aZcwiYZc4hYJa5skNA0ihJD0m6K41Pk7RS0lOSbpK0f/3KNLN6GUxP4GJgba/xy4ErI2I68BKwsJaFmVljlBUCkkrAR4Fr0riA04Bb0yyLgXPqUaCZ1Ve5PYFvAF8CdqbxicDLEdGdxjcDe/2NZEmLJHVK6hzK36+a5WrAEJD0MWBrRKyu5AUi4uqI6IiIjra2tkqaMLM6KudkodnAXElzgFbgYOCbwHhJLak3UAK21K9MM6uXAXsCEfGViChFRDtwPvDjiPgkcA9wbpptPrCkblWaWd1Uc57Al4EvSHqK4hhB9bc4MbOGG9S1AxGxAliRhjcAs2pfkpk1ks8YNMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDL3IAhIKlV0ipJj0h6QtLX0vRpklZKekrSTZL2r3+5ZlZr5fQEXgdOi4gTgJnAmZLeB1wOXBkR04GXgIX1K9PM6mXAEIjCa2l0dPoL4DTg1jR9MXBOXSo0s7oq65iApFGSHga2AsuAXwIvR0R3mmUzMKWfZRdJ6pTU2dXVVYuazayGygqBiOiJiJlACZgFHFfuC0TE1RHREREdbW1tFZZpZvUyqG8HIuJl4B7gZGC8pJb0VAnYUuPazKwByvl2oE3S+DR8IPBhYC1FGJybZpsPLKlXkWZWPy0Dz8LhwGJJoyhC4+aIuEvSGuBGSX8DPARcW8c6zaxOBgyBiHgUOHEv0zdQHB8ws2HMZwyaZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGVuwBCQNFXSPZLWSHpC0sVp+gRJyyStT4+H1r9cM6u1cnoC3cAXI2IG8D7gIkkzgEuA5RFxNLA8jZvZMDNgCETEcxHxYBreDqwFpgBnA4vTbIuBc+pVpJnVz6COCUhqB04EVgKTI+K59NTzwOR+llkkqVNSZ1dXVxWlmlk9lB0CksYCtwGfi4hXez8XEQHE3paLiKsjoiMiOtra2qoq1sxqr6wQkDSaIgCuj4jb0+RfSTo8PX84sLU+JZpZPZXz7YCAa4G1EXFFr6fuBOan4fnAktqXZ2b11lLGPLOBTwOPSXo4TfsqcBlws6SFwNPAefUp0czqacAQiIh7AfXz9Om1LcfMGs1nDJplziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZW7AEJD0bUlbJT3ea9oEScskrU+Ph9a3TDOrl3J6AtcBZ/aZdgmwPCKOBpancTMbhgYMgYj4KfBin8lnA4vT8GLgnBrXZWYNUukxgckR8Vwafh6Y3N+MkhZJ6pTU2dXVVeHLmVm9VH1gMCICiH08f3VEdERER1tbW7UvZ2Y1VmkI/ErS4QDpcWvtSjKzRqo0BO4E5qfh+cCS2pRjZo1WzleENwD3A8dK2ixpIXAZ8GFJ64EPpXEzG4ZaBpohIub189TpNa7FzJrAZwyaZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmasqBCSdKWmdpKckXVKrosyscSoOAUmjgH8BzgJmAPMkzahVYWbWGNX0BGYBT0XEhoh4A7gROLs2ZZlZo1QTAlOAZ3uNb07TzGwYqfuBQUmLJHVK6uzq6qr3y5nZIFUTAluAqb3GS2naHiLi6ojoiIiOtra2Kl7OzOqhmhB4ADha0jRJ+wPnA3fWpiwza5SWSheMiG5JnwF+BIwCvh0RT9SsMjNrCEVE415M6gKeLmPWScALdS6nUUbKuoyU9YA81+XIiNjr/nhDQ6BckjojoqPZddTCSFmXkbIe4HXpy6cNm2XOIWCWuaEaAlc3u4AaGinrMlLWA7wuexiSxwTMrHGGak/AzBrEIWCWuSEVApKmSrpH0hpJT0i6uNk1VUJSq6RVkh5J6/G1ZtdULUmjJD0k6a5m11INSZskPSbpYUmdza6nUpLGS7pV0pOS1ko6udK2Kj5jsE66gS9GxIOSxgGrJS2LiDXNLmyQXgdOi4jXJI0G7pX0w4j4ebMLq8LFwFrg4GYXUgMfjIjhfrLQN4GlEXFuOm3/oEobGlI9gYh4LiIeTMPbKf7TDbvLk6PwWhodnf6G7RFYSSXgo8A1za7FQNIhwCnAtQAR8UZEvFxpe0MqBHqT1A6cCKxsbiWVSd3nh4GtwLKIGJbrkXwD+BKws9mF1EAAd0taLWlRs4up0DSgC/iPtIt2jaQxlTY2JENA0ljgNuBzEfFqs+upRET0RMRMikusZ0k6vtk1VULSx4CtEbG62bXUyPsj4j0Ut8W7SNIpzS6oAi3Ae4B/jYgTgV8DFd/jc8iFQNqHvg24PiJub3Y91UrdtHuAM5tdS4VmA3MlbaK4hdxpkv6zuSVVLiK2pMetwB0Ut8kbbjYDm3v1Lm+lCIWKDKkQkCSK/Zy1EXFFs+uplKQ2SePT8IHAh4Enm1tVZSLiKxFRioh2intG/DgiPtXksioiaUw64EzqPn8EeLy5VQ1eRDwPPCvp2DTpdKDig+dD7duB2cCngcfS/jTAVyPiv5pYUyUOBxanOzLvB9wcEcP6q7URYjJwR/FZQwvw3YhY2tySKvbnwPXpm4ENwB9X2pBPGzbL3JDaHTCzxnMImGXOIWCWOYeAWeYcAmaZcwiYZc4hMMRJapf0R3Vo95qBfkVa0nWSzt3L9FNHwCXFw34dasUh0GCSBnuCVjtQ8xCIiAubdYl2OolqWBsJ67CLQ2Af0qfwWknfSjcHuVvSgZLeIWlpuhLtZ5KOS/N/XNLKdGXXf0uanKZfKuk7ku4DvpNOK75N0gPpb3aa7wPpZhcPpzbGAZcBv5emfb6fOhdIuj3VtF7SP/R67iOS7pf0oKRb0sVZSFohqSMNL5T0i3QjlG9JuqpX86dI+h9JG/r0Cg6W9ANJ6yT9m6T9Ulvz0k07Hpd0ea86XpP0dUmPACdLukzFzWMelfSP+/g3uE7SP/Wtoe8nuaSrJC1Iw5sk/X16zzolvUfSjyT9UtKflrEO/b1nmyRdLulB4BP91TzsRIT/+vmj+BTuBmam8ZuBTwHLgaPTtN+hOJ8e4FB2n4V5IfD1NHwpsBo4MI1/l+JqNoAjKK6VAPg+MDsNj6U4tfVU4K4B6lxAceroIUArxa88TaX4dZqfAmPSfF8G/jINrwA6gLcDm4AJFPc9+BlwVZrnOuAWig+LGcBTafqpwA7gKIqfoFsGnJvaegZoS7X/GDgnLRPAeWl4IrCu13s1fh/rtq8a7uo131XAgjS8CfizNHwl8CgwLtX1qwHWYV/v2SbgS83+f1nrv6F27cBQtDEidl3HsJoiGH4XuCWdgw5wQHosATdJOhzYH9jYq507I+L/0vCHgBm9lj84fdrcB1wh6Xrg9ojY3GuegSyPiFcAJK0BjgTGU2w496V29gfu77PcLOAnEfFiWvYW4Jhez38vInYCa3b1bJJVEbEhLXMD8H7gTWBFRHSl6ddT3Pzie0APxdWhAK9QbIDXpk/zgfbN+6thX3b9OO5jwNgoblKzXdLrShd39bMOO9j3e3ZTma8/bDgEBvZ6r+EeiotQXo7iXgF9/TNwRUTcKelUih7ALr/uNbwf8L6I2NFn+csk/QCYQ/Gf8Iwq6mwBRHFDk3mDaGdf7fZOpL4XnQx0EcqOiOiBt37MdhbF1W/nAp8BThtkDd3suTvb2s8yO/ssv5Pd/+/3tg4DvWe/7mf6sOVjAoP3KrBR0ieguPxZ0gnpuUOALWl4/j7auJviKjBSGzPT4zsi4rGIuJzip9+PA7ZTdGUr8XNgtqTpqf0xko7pM88DwAckHarioOUflNn2LBU/S78f8IfAvcCq1NYkFQfO5gE/6btg6vUcEsXVoZ8HTug7TxmepuhNHZA+2U+voI29rUM579mI4hCozCeBhekg1xPA2Wn6pRS7CavZ9y/FfhboSAfF1gC7DlZ9Lh1Qe5Sia/1Div3ZHhV3Lt7rgcH+pG75AuCG1Ob9FMHSe54twN9RbMD3Uez3vlJG8w9Q7IevpdjtuSMinqO4w809wCPA6ohYspdlxwF3pZruBb4wmPVKdT9LcYzm8fT40GDb6GcdBnzPRhpfSmxIGhvFnZFbKO628+2IuKPZdVljuCdgAJequInL4xSfiN9rcj3WQO4JDCPpQOHlfSZvjIjfb0Y9tSTpL/jt795viYi/bUY9OXEImGXOuwNmmXMImGXOIWCWOYeAWeb+H3e2KWNGTRy7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}